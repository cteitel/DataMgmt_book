# Data Manipulation with R, Part 2 {#manipulation}

Much of this lesson draws from The Carpentries' [Data Analysis and Visualization in R for Ecologists](https://datacarpentry.github.io/R-ecology-lesson/index.html) workshop, which is published under a [CC-BY 4.0](https://datacarpentry.github.io/R-ecology-lesson/LICENSE.html) license.

## Objectives

* Be able to use a split-apply-combine approach to summarize data sets
* Understand how to augment datasets, both by adding observations and by adding variables
* Understand different types of joins and relates

## Additional reading

Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science (2e). Chapter 3: Data transformation, sections 3.5-3.7. Available: https://r4ds.hadley.nz/data-transform.html

Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science (2e). Chapter 5: Data tidying. Available: https://r4ds.hadley.nz/data-transform.html

## Grouping and summarizing data

One of the most common tasks in data exploration is summarizing data. For example, we might want to know the mean of a response variable across a treatment, or how many samples were taken on a given day, and so on. `dplyr` allows us to easily summarize data by combining the functions `group_by()` and `summarize()`. For example:

```{r}
library(tidyverse)
urban_data <- read_csv("data/raw/Murray-Sanchez_urban-wildlife.csv")
urban_data %>%
  group_by(host.class) %>%
  summarize(mean_r = mean(r, na.rm=T), n = n())
```

We end up with a mean value of *r* for each host group and the number of records in that group. A common function you will use when grouping is `n()`, which gives the current group size. Other common summary functions include:

* `n_distinct()`, which gives the number of unique values in a group and takes a column name as its argument;
* quantitative summaries, like `mean()`, `median()`, `sd()`, and `sum()`;

```{r}
urban_data %>%
  group_by(host.class) %>%
  summarize(mean_r = mean(r, na.rm=T), n = n(), n_studies = n_distinct(study))
```

## Combining and augmenting data sets

Often, we have multiple data sets that relate to each other in one way or another, or we want to combine multiple sources of the same data. For example, we might have separate data sheets from multiple field seasons and want to combine them. Or, we might have one data table that describes characteristics of plots and one that describes characteristics of trees, and we want to add the plot information for each tree. 

### Binding rows and columns

Adding ("binding") rows and columns is the easiest way to add data to a data frame. For example, if we have two separate data sets, we can add more rows with `bind_rows`:

```{r}
ds1 <- data.frame(plot = 1:10, observer = "Me", n_obs = sample(1:100, 10), date = "2024-04-01")
ds2 <- data.frame(plot = 1:10, observer = "You", n_obs = sample(1:100, 10), date = "2025-01-01")

ds_full <- bind_rows(ds1, ds2)
nrow(ds_full)
head(ds_full)
tail(ds_full)
```

`bind_rows` looks for column names to know how to match up the data. This is great when your columns are in different orders, but be careful with column names:

```{r}
ds1 <- data.frame(plot = 1:10, observer = "Me", n_obs = sample(1:100, 10))
ds2 <- data.frame(Plot = 1:10, obs = "You", N = sample(1:100, 10))

ds_full <- bind_rows(ds1, ds2)
nrow(ds_full)
head(ds_full)
```

We can also add more information with `bind_cols`, though joins (below) are usually a better way to add columns to a data set. `bind_cols` is also useful for creating new data frames from vectors:

```{r}
plots <- c(1:10)
observers <- rep("Me", 10)
N <- sample(1:100, 10)

ds1 <- bind_cols(plot = plots, observer = observers, n_obs = N)
```

### Joins

There are several types of join. The most common types are left join, inner join, or full join. To understand this terminology, consider this: whenever you are joining two tables, the first table you mention (the one to which you’re joining) is called the left table, whereas the second table (the one you’re joining to the first) is called the right table. With a left join, you keep all the records in the left table and add information from the right table whenever there’s a matching row. A full join means that you retain all rows from both tables, matching them whenever possible. An inner join means that you only retain the rows that match between the two tables.

Let's practice with the Murray et al. data. First, we need to download some extra data to add. The EltonTraits database provides foraging attributes and body mass for birds and mammals. These might be interesting, for example to see if species' responses to urbanization vary depending on their body size or foraging traits. These data can be downloaded from [Figshare](https://figshare.com/collections/EltonTraits_1_0_Species-level_foraging_attributes_of_the_world_s_birds_and_mammals/3306933).

```{r}
elton <- read_csv("data/raw/EltonTraits/BirdFuncDat.csv")
urban_birds <- filter(urban_data, host.class == "birds")
```

This can be a little tricky: EltonTraits and the Murray et al. database use different taxonomies, so there are a few birds in `urban_birds` that aren't in EltonTraits. To really use these data we would need to correct those discrepancies, but for now this will help illustrate the different types of joins. 

```{r}
# Which birds are missing?
urban_birds %>%
  filter(!host.species %in% elton$Scientific) %>%
  select(host.species)
```

Left joins are probably the most common type you will use, because they help add new information to a reference data set.

```{r}
urban_traits <- left_join(urban_birds, elton, by = c("host.species" = "Scientific"))
ncol(urban_birds)
ncol(urban_traits)
```

The `by` argument is the second-trickiest part of a join (the trickiest part is making sure it did what you expected). Here, we specify that we want to match up values in the column `host.species` from the first data frame with values in the column `Scientific` in the second data set. The `tidyverse` join functions will automatically use columns with the same names if you don't specify `by`. If you specify a single character, it will look for columns with that name in both data sets. Finally, you can specify multiple columns (for example, if you had a study design with `block` nested within `plot` and you wanted to match both).

An inner join would be similar, but would eliminate those species that are not in EltonTraits, because they are not present in both data sets:

```{r}
urban_traits <- inner_join(urban_birds, elton, by = c("host.species" = "Scientific"))
nrow(urban_birds)
nrow(urban_traits)
```

An full join would be helpful if you want to include all the effect sizes and all the trait information in a single data set, regardless of whether you have the other information:

```{r}
urban_traits <- full_join(urban_birds, elton, by = c("host.species" = "Scientific"))
ncol(urban_traits)
nrow(urban_traits)
```

## Pivoting between wide and long format

We talked about wide and long formats when discussing data entry and spreadsheets, but it is still useful to know how to transform your data sets once they get into R. Why? Well, sometimes you will have a data set that isn't set up in long form. Other times, wide form is useful for visualization or making tables.

### Long to wide

Let's start with a data set in long form: one observation per row, one variable per column. The urban wildlife data set follows this structure. Let's say we want to know how many studies we have per year and health metric:

```{r}
urban_data %>%
  group_by(health, YEAR) %>%
  summarize(n = n())
```

To present this in a paper, we might consider transforming it to wide form:

```{r}
urban_data %>%
  group_by(health, YEAR) %>%
  summarize(n = n()) %>%
  pivot_wider(id_cols = YEAR, names_from = health, values_from = n, values_fill = 0)
```

Here we use the `pivot_wider()` function from the `tidyr` package (part of the `tidyverse`). Here `id_cols` tells the function which variable to use to define a row in the new table. `names_from` defines the column in the long-form data that will become the column names, and `values_from` defines the column in the long-form data that will be used to fill those columns. Finally, you don't always need `values_fill`, but when an id-name combination is missing in the original data, this tells the funciton what to include in the new table (by default, it will be `NA`).

Pivoting data frames takes some practice. One of the most common pitfalls in going from wide to long form is that each id-name combination needs to have a unique value. For example, let's say we first summarized the data by both year and host habitat:

```{r}
urban_data %>%
  group_by(health, YEAR, aqterr) %>%
  summarize(n = n()) %>%
  pivot_wider(id_cols = YEAR, names_from = health, values_from = n)
```

You see this gave us a warning message and that the new columns are lists. This is because some of the cells in this wide data frame now have more than one element (i.e., years where both aquatic and terrestrial hosts had data for a given health metric). We can fix this by including `aqterr` as either and ID or a names column:

```{r}
urban_data %>%
  group_by(health, YEAR, aqterr) %>%
  summarize(n = n()) %>%
  pivot_wider(id_cols = c(YEAR, aqterr), names_from = health, values_from = n, values_fill = 0) %>%
  head()

urban_data %>%
  group_by(health, YEAR, aqterr) %>%
  summarize(n = n()) %>%
  pivot_wider(id_cols = YEAR, names_from = c(health, aqterr), values_from = n, values_fill = 0) %>%
  head()
```

In the second case, we end up with the health and habitat data being sandwiched together into new column names.

### Wide to long

In the other direction, we sometimes end up with data that is wide and needs to be long. For example, let's say we have a data set with counts by site across years:

```{r}
survey_data <- sample(0:100, 10*12, replace = T) %>% 
  matrix(nrow = 10, ncol = 12) %>%
  as.data.frame() %>%
  setNames(str_c("site",1:12)) %>%
  bind_cols(year = 2000:2009) %>% 
  select(year, everything())
survey_data
```

(Side note: this is an example of how to simulate data to test code. We can go into this in more detail later in the course.)

```{r}
survey_data %>%
  pivot_longer(cols = -year, names_to = "site", values_to = "count")
```

Here, we use the `pivot_longer()` function, also from `tidyr` and identify the columns that we want to pivot with `cols`. Because we want to get values from all the columns *except* the `year` column, we use a minus sign (-) to indicate that. We could also list all the columns (`c(site1, site2, site3)`), but this would be unwieldy. We also specify the column names of the new columns we are creating: one for what were the column names in the old wide data frame (`names_to`) and one for what were the values. 

One common challenge with pivoting longer is when we have a data frame that has more columns than the ones we want to include in the long data. For example, let's say our survey data also included information about the observer:

```{r, error = T}
survey_data <- mutate(survey_data, observer = sample(c("A","B","C"), nrow(survey_data), replace = T))
survey_data %>%
  pivot_longer(cols = -year, names_to = "site", values_to = "count")
```

Here, we get an error because `pivot_longer()` is trying to make a single column ("count") that includes both numbers and a character. We can get around this by removing the observer from the data before pivoting or, if we want that information, including it in our column specification:

```{r}
survey_data %>%
  select(-observer) %>%
  pivot_longer(cols = -year, names_to = "site", values_to = "count") %>%
  head()

survey_data %>%
  pivot_longer(cols = -c(year, observer), names_to = "site", values_to = "count") 
```




